I want the code for a web application.
It should be able to make a recording, with a pause and stop button. Store that recording in my google cloud bucket and local drive every time under a unique name in uploads folder. 
Then it should the google speech to text api to convert the audio into text. It should store the text in the uploads folder as well under a unique name local and on cloud as well.
The it should process the text that was converted through speech to text via openAI under the prompt "Provide a summary of this conversation: SPEECHTOTEXTCONVERTEDTEXT"
Then it should display the text on webpage and console.
Basically, record and save. convert speech to text. process text through ai. display original and processed.Make sure its simple and works. 
start off by giving the code for the front end
import os
import uuid
import subprocess
from flask import Flask, request, jsonify, render_template
from google.cloud import speech, storage
from google.oauth2 import service_account
import openai

app = Flask(__name__)

# Configure these variables with your own details
BUCKET_NAME = "audioforweb"
GOOGLE_CLOUD_CREDENTIALS_FILE = "C:/Users/Rohan/OneDrive/Documents/audio-web-app/credentials.json"
OPENAI_API_KEY = "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"
LOCAL_UPLOADS_FOLDER = "uploads"

# Ensure the uploads folder exists
os.makedirs(LOCAL_UPLOADS_FOLDER, exist_ok=True)

# Initialize the Google Cloud client
storage_client = storage.Client.from_service_account_json(GOOGLE_CLOUD_CREDENTIALS_FILE)
bucket = storage_client.bucket(BUCKET_NAME)

# Initialize OpenAI client
openai.api_key = OPENAI_API_KEY

@app.route('/')
def index():
    return render_template('index.html')

def upload_blob(bucket_name, source_file_path, destination_blob_name):
    """Uploads a file to the specified bucket."""
    try:
        storage_client = storage.Client.from_service_account_json(GOOGLE_CLOUD_CREDENTIALS_FILE)
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(destination_blob_name)
        blob.upload_from_filename(source_file_path)
        print(f"File {source_file_path} uploaded to {destination_blob_name}.")
    except Exception as e:
        print(f"Failed to upload to Google Cloud Storage: {e}")
        raise

@app.route('/upload', methods=['POST'])
def upload_audio():
    file = request.files.get('audioFile')
    if not file:
        return jsonify({'error': 'No audio file provided'}), 400

    # Save locally
    unique_id = uuid.uuid4().hex
    raw_local_filename = f"{unique_id}_raw.wav"
    raw_local_filepath = os.path.join(LOCAL_UPLOADS_FOLDER, raw_local_filename)
    file.save(raw_local_filepath)

    # Convert audio to desired format using FFmpeg
    local_filename = f"{unique_id}.wav"
    local_filepath = os.path.join(LOCAL_UPLOADS_FOLDER, local_filename)
    ffmpeg_command = [
        'ffmpeg',
        '-i', raw_local_filepath,
        '-acodec', 'pcm_s16le',
        '-ar', '44100',
        '-ac', '1',
        local_filepath
    ]
    process = subprocess.run(ffmpeg_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if process.returncode != 0:
        print(f"FFmpeg error: {process.stderr.decode()}")
        return jsonify({'error': 'FFmpeg processing failed'}), 500

    # Upload to Google Cloud Storage
    cloud_filename = f"audio/{local_filename}"
    try:
        upload_blob(BUCKET_NAME, local_filepath, cloud_filename)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

    # Transcribe audio file
    gcs_uri = f"gs://{BUCKET_NAME}/{cloud_filename}"
    transcript = transcribe_audio(gcs_uri)
    
    # Summarize the transcript with OpenAI
    summary = summarize_text(transcript)

    # Return transcript and summary
    return jsonify({'transcript': transcript, 'summary': summary})

def transcribe_audio(gcs_uri):
    client = speech.SpeechClient.from_service_account_json(GOOGLE_CLOUD_CREDENTIALS_FILE)
    audio = speech.RecognitionAudio(uri=gcs_uri)
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=44100,
        language_code="en-US",
        enable_automatic_punctuation=True
    )
    operation = client.long_running_recognize(config=config, audio=audio)
    response = operation.result(timeout=90)
    return " ".join(result.alternatives[0].transcript for result in response.results)

def summarize_text(text):
    response = openai.Completion.create(
        engine="gpt-3.5-turbo-instruct",
        prompt=f"Provide a summary of this conversation: {text}",
        temperature=0.7,
        max_tokens=150,
        top_p=1.0,
        frequency_penalty=0.0,
        presence_penalty=0.0
    )
    return response.choices[0].text.strip()

if __name__ == '__main__':
    app.run(debug=True)
